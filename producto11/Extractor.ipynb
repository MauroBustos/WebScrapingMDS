{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.10",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "86580b34d9e683017e2f00b9de15ecbc4b8113474bcd241888a2f2402baffccf"
            }
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "## Librerias a utilizar"
            ],
            "metadata": {
                "azdata_cell_guid": "cfd085db-8bc7-4f03-bcc7-7365c9a981a0"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "#!pip install pyarrow"
            ],
            "metadata": {
                "azdata_cell_guid": "2316c575-9178-4553-8990-9506e622e9be",
                "language": "python"
            },
            "outputs": [],
            "execution_count": 47
        },
        {
            "cell_type": "code",
            "source": [
                "# Tratamiento de datos\n",
                "# ==============================================================================\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import re\n",
                "import time\n",
                "from datetime import date\n",
                "import pyarrow\n",
                "\n",
                "# Manejo Web, paginas y webScrapping\n",
                "# ==============================================================================\n",
                "import urllib.request\n",
                "from selenium import webdriver\n",
                "from selenium.webdriver.common.keys import Keys\n",
                "from selenium.webdriver.common.by import By\n",
                "from selenium.webdriver.support.ui import WebDriverWait\n",
                "from selenium.webdriver.support import expected_conditions as EC\n",
                "from selenium import webdriver\n",
                "from bs4 import BeautifulSoup as bs\n",
                "\n",
                "\n",
                "# Gráficos\n",
                "# ==============================================================================\n",
                "from matplotlib import pyplot as plt\n",
                "\n",
                "\n",
                "# Configuración warnings\n",
                "# ==============================================================================\\n\",\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')"
            ],
            "metadata": {
                "azdata_cell_guid": "93117478-5ebb-4963-8f55-265bfba64021",
                "language": "python"
            },
            "outputs": [],
            "execution_count": 48
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Funciones "
            ],
            "metadata": {
                "azdata_cell_guid": "f279c069-efaf-4da4-bcb3-9e8016f84a0c"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "def ExtraerLink(linkPage,patron):\n",
                "    lista = []\n",
                "    for tag in linkPage:\n",
                "        valor = tag.get('href')\n",
                "        if(str(valor).find(patron) != -1):\n",
                "            lista.append(valor)\n",
                "    df = pd.DataFrame (lista, columns = ['url'])\n",
                "    df = df.drop_duplicates()\n",
                "    return df\n",
                "def leerUrl(pagina):    \n",
                "    soup = bs(urllib.request.urlopen(pagina).read().decode())\n",
                "    #print(str(soup) )\n",
                "    time.sleep(5)\n",
                "  \n",
                "    return  soup\n",
                "\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "1692e244-c0ed-4679-8719-e29e2c2692e8",
                "language": "python",
                "tags": [
                    "hide_input"
                ]
            },
            "outputs": [],
            "execution_count": 49
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Extraccion de Oferta Laborales Linkedin"
            ],
            "metadata": {
                "azdata_cell_guid": "2adb78e6-fbf0-4cab-8d16-51bdf3f8f84c"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Instantiate the webdriver with the executable location of MS Edge\n",
                "# Provide the full location of the path to recognise correctly\n",
                "PATH = 'msedgedriver.exe'\n",
                "options = webdriver.EdgeOptions()\n",
                "options.add_argument('--start-maximized')\n",
                "options.add_argument('--disable-extensions')\n",
                "options.add_argument('disable-dev-shm-usage')\n",
                "options.add_argument('--no-sandbox')\n",
                "options.add_argument('--blink-settings=imagesEnabled=false')\n",
                "options.add_argument('--headless')\n",
                "driver = webdriver.Edge(PATH, options= options)"
            ],
            "metadata": {
                "azdata_cell_guid": "7cdac56d-dbef-408c-8641-50237c90d18c",
                "language": "python"
            },
            "outputs": [],
            "execution_count": 50
        },
        {
            "cell_type": "code",
            "source": [
                "# Browser will get navigated to the gi((ven URL\n",
                "driver.get('https://www.linkedin.com/jobs/search/?keywords=Data%20Scientist&location=Chile&locationId=&geoId=104621616&f_TPR=r86400&position=1&pageNum=0')\n",
                "time.sleep(3)"
            ],
            "metadata": {
                "azdata_cell_guid": "95cf7ccd-1e64-49e4-aa6b-c4531ea4d300",
                "language": "python"
            },
            "outputs": [],
            "execution_count": 51
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Preprocesamiento de Pagina de Empleo LinkedIn\n",
                "Se crea un Dataframe con los link de las paginas de Oferta"
            ],
            "metadata": {
                "azdata_cell_guid": "4e41e9da-bc6d-4766-abb1-981159cbd843"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "linkedin_soup = bs(driver.page_source.encode(\"utf-8\"), \"html\")\n",
                "#print(linkedin_soup)\n",
                "patron = '/jobs/view/'\n",
                "df = ExtraerLink(linkedin_soup('a'),patron)\n",
                "df.info()"
            ],
            "metadata": {
                "azdata_cell_guid": "9dccf09d-20ab-4f17-9935-3c234729889d",
                "language": "python"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 27 entries, 0 to 26\nData columns (total 1 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   url     27 non-null     object\ndtypes: object(1)\nmemory usage: 432.0+ bytes\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 52
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Creacion de DF con resultado de paginas\n"
            ],
            "metadata": {
                "azdata_cell_guid": "4f920048-abd2-40ea-bd89-f56c9bb51eb0"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "columns = [\"url\", \"contenido\"]\n",
                "dffinal = pd.DataFrame(columns=columns)\n",
                "\n",
                "for i in range(len(df)-1):\n",
                "    link = str(df.iloc[i]['url'])\n",
                "\n",
                "    #name = get_name(driver,link)   \n",
                "    #print(name)\n",
                "    linkedin_soup1 = leerUrl(link.split('?')[0]) \n",
                "    #print(linkedin_soup1)\n",
                "    if str(linkedin_soup1) == \"Not Found\":\n",
                "        break\n",
                " \n",
                "    parametro = 'show-more-less-html__markup'\n",
                "    links_divs = linkedin_soup1.findAll(\"div\", {\"class\": parametro})\n",
                "    links_divs = str(links_divs)\n",
                "    dffinal = dffinal.append(\n",
                "                {\n",
                "                    \"url\": link,\n",
                "                    \"contenido\": links_divs,\n",
                "                },\n",
                "                ignore_index=True,\n",
                "            )"
            ],
            "metadata": {
                "azdata_cell_guid": "8db2730f-4d72-4ba4-8dd5-a9ef5c1e189f",
                "language": "python"
            },
            "outputs": [],
            "execution_count": 53
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Guardar DataFrame con valores Crudos, para preprocesamiento de datos."
            ],
            "metadata": {
                "azdata_cell_guid": "4b8aba8d-b5f4-4762-ade4-08d467e5fd08"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Traza\n",
                "#with pd.option_context('display.max_colwidth', None):\n",
                "#    display(dffinal)\n",
                "\n",
                "dffinal.to_parquet(\"output/df_\"+date.today().strftime(\"%d%m%Y\")+'.parquet', engine='pyarrow')"
            ],
            "metadata": {
                "azdata_cell_guid": "edc566a3-bc49-4d39-98f0-772d6797979d",
                "language": "python"
            },
            "outputs": [],
            "execution_count": 54
        },
        {
            "cell_type": "code",
            "source": [
                "dffinal.contenido[2]"
            ],
            "metadata": {
                "azdata_cell_guid": "1f5507ad-60f6-4883-9970-dd6df1e73832",
                "language": "python"
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": "'[<div class=\"show-more-less-html__markup show-more-less-html__markup--clamp-after-5\">\\n<p>A globally recognized biotechnology startup who develop hyperfood (therapeutically functional foods made by artificial intelligence).</p><p><br/></p><p>Joining their global machine learning space, you will be building next-generation human food  using Machine Learning/AI to help expand our business footprint, you could be doing ground-breaking work that brings our iconic, global brand into the future. If you love to work help human with healthy food with Machine Learning/AI using the latest technology, we’ll support you with an open and learning environment to grow your career.</p><p><br/></p><p><u>Requirements:</u></p><p><br/></p><ul><li>Computer science or related degree</li><li>At least 2+ years of experience in ML development, ideally Python as a programming language and Pytorch</li><li>Highly collaborative individuals who want to work in flat structured teams and a desire to own projects</li><li>At least 1+ years experience in AWS Sagemaker</li></ul><p><br/></p><p>Person looking for a highly purpose and personal and professional growth in a unique biotech startup to help humankind</p>\\n</div>]'"
                    },
                    "metadata": {},
                    "execution_count": 55,
                    "output_type": "execute_result"
                }
            ],
            "execution_count": 55
        },
        {
            "cell_type": "code",
            "source": [
                "str(df.iloc[0]['url'])"
            ],
            "metadata": {
                "azdata_cell_guid": "ef067919-4f57-440c-8c3a-5bfbd6286f43",
                "language": "python"
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": "'https://cl.linkedin.com/jobs/view/cient%C3%ADfico-de-datos-at-ibm-3252800220?refId=MOw5HN9ZLqp%2FZikoNyR0lA%3D%3D&trackingId=3B9h9aVJ6JQlgXLQREimPw%3D%3D&position=1&pageNum=0&trk=public_jobs_jserp-result_search-card'"
                    },
                    "metadata": {},
                    "execution_count": 46,
                    "output_type": "execute_result"
                }
            ],
            "execution_count": 46
        }
    ]
}